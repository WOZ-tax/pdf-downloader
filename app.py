import streamlit as st
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseUpload
import io
import re
import os

# --- èªè¨¼è¨­å®š (Streamlit Secretsã‹ã‚‰èª­ã¿è¾¼ã‚€) ---
try:
    # Secretsã‹ã‚‰è¾æ›¸ã¨ã—ã¦èª­ã¿è¾¼ã‚€
    key_dict = dict(st.secrets["gcp_service_account"])
except Exception:
    st.error("è¨­å®šã‚¨ãƒ©ãƒ¼: Secretsã« [gcp_service_account] ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.stop()

# --- é–¢æ•°ç¾¤ ---
def get_drive_service():
    creds = service_account.Credentials.from_service_account_info(
        key_dict, scopes=['https://www.googleapis.com/auth/drive'])
    return build('drive', 'v3', credentials=creds)

def extract_folder_id(url):
    match = re.search(r'folders/([a-zA-Z0-9_-]+)', url)
    return match.group(1) if match else None

def sanitize(text):
    return re.sub(r'[\\/:*?"<>|]', '_', text).strip()[:100]

def save_to_drive(service, folder_id, name, content):
    meta = {'name': name, 'parents': [folder_id]}
    media = MediaIoBaseUpload(io.BytesIO(content), mimetype='application/pdf')
    service.files().create(body=meta, media_body=media, fields='id').execute()

# --- ã‚¢ãƒ—ãƒªç”»é¢ ---
st.set_page_config(page_title="PDF Hunter", page_icon="ğŸ“‚")
st.title("ğŸ“‚ PDF Hunter")

with st.form("form"):
    target = st.text_input("Webãƒšãƒ¼ã‚¸URL", "https://www.nta.go.jp/about/organization/ntc/soshoshiryo/kazei/2023/index.htm")
    drive = st.text_input("ä¿å­˜å…ˆDriveãƒ•ã‚©ãƒ«ãƒ€URL")
    btn = st.form_submit_button("é–‹å§‹")

if btn:
    fid = extract_folder_id(drive)
    if not fid:
        st.error("Drive URLãŒç„¡åŠ¹ã§ã™")
        st.stop()
    
    status = st.empty()
    try:
        svc = get_drive_service()
        res = requests.get(target)
        res.encoding = res.apparent_encoding
        soup = BeautifulSoup(res.text, 'html.parser')
        
        # PDFãƒªãƒ³ã‚¯ã‚’æŠ½å‡º
        links = [l for l in soup.find_all('a', href=True) if l['href'].lower().endswith('.pdf')]
        
        if not links:
            st.warning("PDFãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            st.stop()
            
        bar = st.progress(0)
        for i, l in enumerate(links):
            bar.progress((i+1)/len(links))
            url = urljoin(target, l['href'])
            name = sanitize(l.get_text(strip=True)) + ".pdf" if l.get_text(strip=True) else os.path.basename(l['href'])
            
            status.text(f"ä¿å­˜ä¸­: {name}")
            try:
                save_to_drive(svc, fid, name, requests.get(url).content)
            except Exception as e:
                st.warning(f"å¤±æ•—: {name} ({e})")
        
        status.success(f"å®Œäº†ï¼ {len(links)} ä»¶ä¿å­˜ã—ã¾ã—ãŸ")
        st.balloons()
        
    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
